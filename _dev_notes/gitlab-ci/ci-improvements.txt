PACKAGES
Packages are built in each module in the build process.
There is no shared build for the modules.
    Question: How can the packages be a shared module that is imported (mounted) in the module containers?

    Use docker cache from initial build layer, to inline dependency packages to module builds:
    https://circleci.com/developer/orbs/orb/circleci/docker#usage-with-cache-from

    Builder layer => withcachefrom Builderlayer/packages/ => mount into module build as a volume.
    (will have to alter Dockerfiles as well for this config) :)

KUBERNETES DEPLOYMENT IMAGE APPLY
Modules are applied in kubernetes cluster using container-image-updates method.
passing a syntax of value pairs: 
CONTAINER_NAME_1=CONTAINER_IMAGE_1 CONTAINER_NAME_2=CONTAINER_IMAGE_2 etc
Improve: handle dynamic data using context for differnet modules.
Improve: update the service yaml file whenever an image push is made in ci. 

SCRIPTING
Figure out how to run external scripts in the config.yml, 
    Need a script to increment docker image tag for kubernetes deployment

LIST-CHANGED-MODULES
* This is not working correctly, need to resolve it.

* handle different digests for multiple module builds

TODO: (NECESSARY)
docker image builds should only happen for master branch, not for pull requests.
1. add a parameter to publish builds, and deploy to cluster

Efficient CI To Build Modules and Dependencies

1. include a gitlab-ci.yml file in each module.

2. <module>/gitlab-ci.yml contains:
jobs that extend a base module job, that is dependent on changes from node_modules,
and the path of the module itself.

3. when changes are detected,
the module jobs will run.
lint
test
build
deploy

How can I make this modular? Without adding a configuration file to each module?
# BASE_CONFIG

.modules-list:
  - MODULE:
      - app/shop
      - app/dashboard
      - app/checkout-widget
      - server/main
      - server/location
      - server/payments
      - server/image
    # - supertokens

# .module:
#   rules:
#     # start jobs for when there are changes in the path defined
#     - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
#       changes:
#         - $CHANGES_PATH
#     - when: manual
#       allow_failure: true
#   


lint:
extends: .module_lint
...

test:
extends: .module_test
...

build:
  extends: .module_build
  parallel:
    matrix: !reference [.modules]
  # rules:
  #   # MR
  #   - if: $CI_PIPELINE_SOURCE == "merge_request_event"
  #     changes:
  #       - node_modules
  #       - ${MODULE}/**/*

# deploy:
#   extends: .module_deploy
#   parallel:
#     matrix: !reference [.modules]

# read: https://dev.to/drakulavich/gitlab-ci-cache-and-artifacts-explained-by-example-2opi
# QUESTION: WHEN ARE THE OPTIMAL TIMES TO BUILD THE CACHE?
# WHEN IS IT NOT DESIRABLE TO BUILD THE CACHE?

# I NEED NODE_MODULES DURING DOCKER BUILDS, SO FIGURE OUT A WAY TO ARTIFACT THE DEPENDENCIES INTO DOCKER BUILDS.
# HERE IS THE IDEAL CACHE PROCESS:
# 1. CACHE JOB RUNS:
# DOWNLOAD AND INSTALL DEPENDENCIES FROM A CACHE.
# IF THE CACHE IS STALE, BUILD THE CACHE AGAIN FROM SOURCE.
# 2. CREATE AN ARTIFACT VOLUME FROM THE CACHE DURING THE JOB.
# 3. MOUNT THE VOLUME IN DOCKER BUILD, OR IDEALLY AS A BASE IMAGE IN THE DOCKER BUILD.
# IDEALLY, PUSH THE IMAGE IN DOCKER REGISTRY, SO ITS AVAILABLE OUTSIDE OF GITLAB AS WELL.

question about cache:
can i recover the cache in the first job? or is the node_modules always downloaded as the first job?
====================================
ci optimization
1. cache stage creates cache and artifacts
2. cache .yarn/install-state.gz and node_modules
3. cache key: .cache/modules-sha
if cache changed,
create docker build node_modules image.
push to registry,
then build the remaining images

